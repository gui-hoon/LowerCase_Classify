{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae31fed",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2841d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.transforms as T \n",
    "import torch.nn.init\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe7e4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == \"cuda\": \n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    \n",
    "learning_rate = 1e-3\n",
    "training_epochs = 1000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c831c",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1a7b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_dataset = datasets.ImageFolder(root=\"../MNIST/mset/train/\", transform=T.Compose([T.Grayscale(1),\n",
    "                                                                                           #T.RandomAffine(degrees=(5,5), translate=(0.1, 0.15), scale=(0.85, 0.95)),\n",
    "                                                                                           #T.RandomRotation(10.),\n",
    "                                                                                           T.ToTensor()\n",
    "                                                                                           ]))\n",
    "\n",
    "custom_test_dataset = datasets.ImageFolder(root=\"../MNIST/mset/test/\", transform=T.Compose([T.Grayscale(1),\n",
    "                                                                                         T.ToTensor()\n",
    "                                                                                         ]))\n",
    "\n",
    "train_loader = DataLoader(dataset=custom_train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=custom_test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a52111",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "994e41b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 22195\n",
      "test size: 4571\n",
      "train_dataset_classes_names =  {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n",
      "num classes =  26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"train size: {len(custom_train_dataset)}\")\n",
    "print(f\"test size: {len(custom_test_dataset)}\")\n",
    "print(\"train_dataset_classes_names = \", custom_train_dataset.class_to_idx)\n",
    "print(\"num classes = \",len(custom_train_dataset.class_to_idx))\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2a062",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2469fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(CNN, self).__init__()\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        # Conv -> (?, 28, 28, 128)\n",
    "        # Pool -> (?, 14, 14, 128)\n",
    "        self.layer1 = self.conv1(1, 128)\n",
    "        \n",
    "        # L2 ImgIn shape=(?, 14, 14, 128)\n",
    "        # Conv ->(?, 14, 14, 256)\n",
    "        # Pool ->(?, 7, 7, 256)\n",
    "        self.layer2 = self.conv2(128, 256)\n",
    "        \n",
    "        # L3 ImgIn shape=(?, 7, 7, 256)\n",
    "        # Conv ->(?, 7, 7, 512)\n",
    "        # Pool ->(?, 4, 4, 512)\n",
    "        self.layer3 = self.conv3(256, 512)\n",
    "        \n",
    "        # L4 ImgIn shape=(?, 4, 4, 512)\n",
    "        # Conv ->(?, 4, 4, 26)\n",
    "        # Pool ->(?, 1, 1, 26)\n",
    "        self.gap = self.global_avg_pool(512, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(-1, 26)\n",
    "        return out\n",
    "\n",
    "    def conv1(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=5, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "    def conv2(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=5, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.4))\n",
    "           \n",
    "    \n",
    "    def conv3(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=5, padding=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p=0.4))\n",
    "            \n",
    "     \n",
    "    def global_avg_pool(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=5,padding=2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.BatchNorm1d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152c193",
   "metadata": {},
   "source": [
    "# CNN model, loss, optim, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22366f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "#model = torch.load(\"../weight/Gap_best.pth\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device) # 비용 함수에 소프트맥스 포함\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d427a",
   "metadata": {},
   "source": [
    "# Calculation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6dc7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyCalculation(model, test_loader):\n",
    "    # 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "    Accuracy = 0\n",
    "    model = model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for num, data in enumerate(test_loader):\n",
    "            X_test, Y_test = data\n",
    "            X_test = X_test.to(device)\n",
    "            Y_test = Y_test.to(device)\n",
    "\n",
    "            prediction = model(X_test)\n",
    "            correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "            accuracy = correct_prediction.float().mean() \n",
    "            Accuracy += accuracy / len(test_loader)\n",
    "\n",
    "    return Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac44904",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = len(train_loader)\n",
    "bestepoch = 0\n",
    "bestaccuracy = -1\n",
    "history = {'loss' : [], 'accuracy' : []}\n",
    "\n",
    "for epoch in range(training_epochs): \n",
    "    avg_cost = 0\n",
    "    model.train()\n",
    "    \n",
    "    for num, data in tqdm(enumerate(train_loader)): \n",
    "        X, Y = data\n",
    "        X = X.to(device) \n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    accuracy = accuracyCalculation(model, test_loader)\n",
    "    history['loss'].append(avg_cost.cpu().detach().numpy())\n",
    "    history['accuracy'].append(accuracy.cpu().detach().numpy())\n",
    "    \n",
    "    if accuracy > bestaccuracy:\n",
    "        torch.save(model, \"../weight/Gap_fine8.pth\")\n",
    "        bestaccuracy = accuracy\n",
    "        bestepoch = epoch\n",
    "    \n",
    "    scheduler.step(accuracy) \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "    print(f\"now Accuracy: {accuracy}\")\n",
    "    print(f\"Best Epoch: {bestepoch}, Best Accuracy: {bestaccuracy}\")\n",
    "    \n",
    "print(\"Learning Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = training_epochs\n",
    "\n",
    "# plot loss progress\n",
    "plt.title(\"Train Loss\")\n",
    "plt.plot(range(1,num_epochs+1),history['loss'],label='train loss')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot accuracy progress\n",
    "plt.title(\"Train Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),history['accuracy'],label='accuracy')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1d1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf598f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-adas",
   "language": "python",
   "name": "open-adas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
